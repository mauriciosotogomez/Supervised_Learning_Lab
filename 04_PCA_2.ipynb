{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Customer Satisfaction Analysis\n",
    "\n",
    "A survey in order to evaluate 20 different healthcare structures. 2000 customers have evaluated, with a 1-10 scale, each of six features of the service:\n",
    "\n",
    "1. Courtesy\n",
    "2. Clarity\n",
    "3. Competence\n",
    "4. Condition (of the structure)\n",
    "5. Promptness (of the service)\n",
    "6. Opening times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = pd.read_csv(\"csat.csv\")\n",
    "print(df2.head())\n",
    "\n",
    "df2.describe()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "df2.boxplot()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset scaling and visualizing\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler2 = StandardScaler(copy=False) #or alternatively use MinMaxScaler\n",
    "scaler2.fit(df2.astype(float)) # \n",
    "scaler2.transform(df2.astype(float))\n",
    "df2.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_scaled=pd.DataFrame(scaler2.transform(df2.astype(float))) \n",
    "df2_scaled.columns=df2.columns\n",
    "df2_scaled.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_scaled.boxplot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.apply(lambda s: df2.corrwith(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PCA fit\n",
    "from sklearn.decomposition import PCA\n",
    "# we can choose the number of components e.g. 10, the percentage of the total variance or set it to None (that means it automatically chooses the number of components)\n",
    "pca2 = PCA()\n",
    "pca2.fit(df2_scaled) #The fit learns some quantities from the data, most importantly the \"components\" and \"explained variance\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#let's use the pca to transform the dataset\n",
    "df2_pca = pd.DataFrame(pca2.transform(df2_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Let's analyse what happened\n",
    "#VISUALIZE The amount of variance explained by each of the 10 selected principal components.\n",
    "pd.DataFrame(pca2.explained_variance_).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The percentage of variance explained by each of the selected components.\n",
    "explained_var=pd.DataFrame(pca2.explained_variance_ratio_).transpose()\n",
    "explained_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#VISUALIZE The cumulative percentage of explained variance\n",
    "cum_explained_var=np.cumsum(pca2.explained_variance_ratio_)\n",
    "pd.DataFrame(cum_explained_var).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "ax = sns.barplot( data=explained_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(pca2.components_,index=['PC1','PC2','PC3','PC4','PC5','PC6'],columns=df2.columns)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1st component:\n",
    "\n",
    "The variables\n",
    "\n",
    "   - Condition\n",
    "   - Promptness\n",
    "   - Opening-times\n",
    "\n",
    "show a high correlation with the first component. This component can be summarized as an index of the **structure’s performances**\n",
    "\n",
    "### 2nd component:\n",
    "\n",
    "The variables\n",
    "   - Courtesy\n",
    "   - Clarity\n",
    "   - Competence\n",
    "\n",
    "show a high correlation with the second component. \n",
    "This component can be summarized as an index of the **personnel’s performance**\n",
    "\n",
    "**Notice that the Principal Components have negative values in the variables that they explain.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2_pca.columns=['PC1','PC2','PC3','PC4','PC5','PC6']\n",
    "df2_pca"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p1=sns.scatterplot(x=\"PC1\", y=\"PC2\",\n",
    "              alpha=.3, \n",
    "              data=df2_pca);\n",
    "\n",
    "# add annotations one by one with a loop\n",
    "for line in range(0,df2_pca.shape[0]):\n",
    "     p1.text(df2_pca.PC1[line], df2_pca.PC2[line], line, horizontalalignment='left', size='medium', color='black')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We conclude that \n",
    " - centers 18,11 has a GOOD infrastructure but a BAD service\n",
    " - the group near 1,4,6 has BAD infrastructure but GOOD service quality \n",
    " - the group 0,3,2,9 has GOOD infrastructure and service\n",
    " - center 17 has BAD infrastructure and service!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Breast cancer wisconsin (diagnostic) dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#upload a toy datasets from scikit-learn\n",
    "#sklearn comes with a few small standard datasets that do not require to download any file from some external website\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "dataset = load_breast_cancer() #The breast cancer dataset is a classic and very easy binary classification dataset.\n",
    "\n",
    "#create the dataframe\n",
    "dataset_df = pd.DataFrame(dataset.data)\n",
    "columns = dataset.feature_names\n",
    "dataset_df.columns = columns\n",
    "\n",
    "print(dataset[\"DESCR\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset visualization tools\n",
    "%matplotlib inline\n",
    "dataset_df.boxplot()\n",
    "dataset_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## mtcars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import CSV mtcars\n",
    "cars = pd.read_csv('mtcars.csv',index_col = 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The car types are a mix that includes sedans (Datsun, Ford, Honda,…), luxury sedans (Mercedes, Cadellac,..), muscle cars (Javelin, Challenger, Camaro…) and high-end sports cars (Porsche, Lotus, Maserati, Ferrari…)\n",
    "\n",
    "- \tmpg \tMiles/US Gallon \tmpg is the determinant of fuel efficiency\n",
    "- \tcyl \tNumber of cylinders \tData includes vehicles with 4,6,8 cylinder engines.\n",
    "- \tdisp \tDisplacement (cu.in.) \tDisplacement measures overall volume in the engine as a factor of cylinder circumfrance, depth and total number of cylinders. This metric gives a good proxy for the total amount of power the engine can generate.\n",
    "- \thp \tGross horsepower \tGross horsepower measures the theoretical output of an engine’s power output\n",
    "- \tdrat \tRear axle ratio \tThe rear axle gear ratio indicates the number of turns of the drive shaft for every one rotation of the wheel axle. \n",
    "- \tqsec \t1/4 mile time \tA performance measure, primarily of acceleration. Fastest time to travel 1/4 mile from standstill (in seconds).\n",
    "- \tvs \tV/S \tBinary variable signaling the engine cylinder configuration a V-shape (vs=0) or Straight Line (vs=1). V==0 and S==1. \n",
    "- \tam \tTransmission Type \tA binary variable signaling whether vehicle has automatic (am=0) or manual (am=1) transmission configuration.\n",
    "- \tgear \tNumber of forward gears \tNumber of gears in the transmission.\n",
    "- \tcarb \tNumber of carburetors \tThe number of carburetor barrels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Iris database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "\n",
    "iris = datasets.load_iris()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(iris['DESCR'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#create the dataframe\n",
    "iris_df = pd.DataFrame(iris.data)\n",
    "iris_df.columns = iris.feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
