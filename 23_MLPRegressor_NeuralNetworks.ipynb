{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multi-layer Perceptron Regression\n",
    "\n",
    "Class MLPRegressor implements a multi-layer perceptron (MLP) that trains using backpropagation with no activation function in the output layer, which can also be seen as using the identity function as activation function. Therefore, it uses the square error as the loss function, and the output is a set of continuous values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#Boston Housing Dataset: Load the boston dataset.\n",
    "from sklearn.datasets import load_boston\n",
    "boston = load_boston()\n",
    "\n",
    "#Creating feature and target arrays\n",
    "X, y = boston.data, boston.target\n",
    "columns = boston.feature_names\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler(copy=False).fit(X)\n",
    "scaler.transform(X)\n",
    "\n",
    "'''\n",
    "Multi-layer Perceptron is sensitive to feature scaling, so it is highly recommended to scale your data. \n",
    "For example, scale each attribute on the input vector X to [0, 1] or [-1, +1], \n",
    "or standardize it to have mean 0 and variance 1. Note that you must apply the same scaling \n",
    "to the test set for meaningful results. You can use StandardScaler for standardization.\n",
    "'''\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y,\n",
    "                                                    test_size=0.3,\n",
    "                                                    random_state=42)\n",
    "\n",
    "#DEFINE YOUR REGRESSOR and THE PARAMETERS GRID\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "import numpy as np\n",
    "\n",
    "regressor = MLPRegressor(random_state=0)\n",
    "parameters = {'hidden_layer_sizes': [(10, 5), (20,10,5)],\n",
    "              'solver' : ['sgd'],\n",
    "              'batch_size': [20],\n",
    "              'learning_rate' : ['constant'],\n",
    "              'alpha':10.0 ** -np.arange(1, 3),\n",
    "              'max_iter':[1000]}\n",
    "\n",
    "#DEFINE YOUR GRIDSEARCH \n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(regressor, parameters, cv=3, verbose = 10) #with no params it reduces to a CV\n",
    "\n",
    "gs = gs.fit(X_train,y_train)\n",
    "\n",
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "#Returns the coefficient of determination R^2 of the prediction.\n",
    "#Explained variance score: 1 is perfect prediction\n",
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(gs.predict(X_train),gs.predict(X_train)-y_train, c=\"b\", label=\"training data\")\n",
    "plt.scatter(gs.predict(X_test),gs.predict(X_test)-y_test, c=\"g\", label=\"test data\")\n",
    "plt.xlabel(\"Predicted Values\")\n",
    "plt.ylabel(\"Residuals\")\n",
    "plt.legend(loc=\"upper left\")\n",
    "plt.hlines(y=0, xmin=-10, xmax=50, color=\"r\")\n",
    "plt.xlim([-10,50])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, gs.predict(X_train))) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, gs.predict(X_train)))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, gs.predict(X_train))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, gs.predict(X_train))))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test, gs.predict(X_test))) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, gs.predict(X_test)))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, gs.predict(X_test))))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, gs.predict(X_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPRegressor\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn import metrics\n",
    "\n",
    "scaler = StandardScaler(copy=False).fit(X)\n",
    "scaler.transform(X)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "\n",
    "regressor = MLPRegressor(hidden_layer_sizes= (10,5), \n",
    "                         alpha= 0.1,\n",
    "                         max_iter = 5000)\n",
    "\n",
    "regressor.fit(X_train,y_train)\n",
    "y_train_pred=regressor.predict(X_train)\n",
    "y_pred=regressor.predict(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(\"MAE train: \", metrics.mean_absolute_error(y_train, y_train_pred)) \n",
    "print(\"MSE train: \",metrics.mean_squared_error(y_train, y_train_pred))\n",
    "print(\"RMSE train: \",np.sqrt(metrics.mean_squared_error(y_train, y_train_pred)))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_train, y_train_pred)))\n",
    "\n",
    "print(\"MAE test: \", metrics.mean_absolute_error(y_test,y_pred)) \n",
    "print(\"MSE test: \",metrics.mean_squared_error(y_test, y_pred))\n",
    "print(\"RMSE test: \",np.sqrt(metrics.mean_squared_error(y_test, y_pred)))\n",
    "print(\"r2: \",np.sqrt(metrics.r2_score(y_test, y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
