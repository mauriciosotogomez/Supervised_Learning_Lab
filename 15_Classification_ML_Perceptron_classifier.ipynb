{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification: Multi-layer Perceptron Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#IMPORT DATA\n",
    "import pandas as pd\n",
    "data = pd.read_csv('diabetes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Print class freq. through pandas \n",
    "print(data.groupby('target').size())\n",
    "\n",
    "#some imports to plot \n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "\n",
    "#Visualize Class Counts\n",
    "sns.countplot(y=data.target ,data=data)\n",
    "plt.xlabel(\"count of each class\")\n",
    "plt.ylabel(\"classes\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#gives information about the data types,columns, null value counts, memory usage etc\n",
    "data.info(verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#basic statistic details about the data\n",
    "data.describe(include=\"all\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Separate X and y (explanatory variables and target variable)\n",
    "X = data.iloc[:,0:-1]\n",
    "column_names = list(X) \n",
    "y = data.iloc[:,-1] \n",
    "\n",
    "#X.head()\n",
    "#y.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#SPLIT DATA INTO TRAIN AND TEST SET\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, \n",
    "                                                    test_size =0.30, #by default is 75%-25%\n",
    "                                                    #shuffle is set True by default,\n",
    "                                                    stratify=y,\n",
    "                                                    random_state= 123) #fix random seed for replicability\n",
    "\n",
    "print(X_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Multi-layer Perceptron classifier\n",
    "![MLPC](multilayerperceptron_network.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multi-layer Perceptron classifier'''\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model=MLPClassifier(hidden_layer_sizes=(5, 2),\n",
    "              activation='relu', alpha=0.01, batch_size='auto',              \n",
    "              learning_rate='constant', learning_rate_init=0.001,\n",
    "              max_iter=200, solver='lbfgs', tol=0.0001,\n",
    "              validation_fraction=0.2, verbose=True)\n",
    "\n",
    "# hidden_layer_sizes :  The ith element represents the number of neurons in the ith hidden layer, default (100,) . \n",
    "# activation : {‘identity’, ‘logistic’, ‘tanh’, ‘relu’}, default ‘relu’\n",
    "    #Activation function for the hidden layer.\n",
    "    #        ‘identity’, no-op activation, useful to implement linear bottleneck, returns f(x) = x\n",
    "    #        ‘logistic’, the logistic sigmoid function, returns f(x) = 1 / (1 + exp(-x)).\n",
    "    #        ‘tanh’, the hyperbolic tan function, returns f(x) = tanh(x).\n",
    "    #        ‘relu’, the rectified linear unit function, returns f(x) = max(0, x)\n",
    "# solver : {‘lbfgs’, ‘sgd’, ‘adam’}, default ‘adam’\n",
    "    #      ‘lbfgs’ is an optimizer in the family of quasi-Newton methods.\n",
    "    #        ‘sgd’ refers to stochastic gradient descent.\n",
    "    #        ‘adam’ refers to a stochastic gradient-based optimizer proposed by Kingma, Diederik, and Jimmy Ba\n",
    "# alpha : float, optional, default 0.0001\n",
    "    #L2 penalty (regularization term) parameter.\n",
    "# batch_size :Size of minibatches for stochastic optimizers. When set to “auto”, batch_size=min(200, n_samples)\n",
    "# learning_rate : {‘constant’, ‘invscaling’, ‘adaptive’}, default ‘constant’\n",
    "    #    ‘constant’ is a constant learning rate given by ‘learning_rate_init’.\n",
    "    #    ‘invscaling’ gradually decreases the learning rate at each time step ‘t’ using an inverse scaling exponent of ‘power_t’. effective_learning_rate = learning_rate_init / pow(t, power_t)\n",
    "    #    ‘adaptive’ keeps the learning rate constant to ‘learning_rate_init’ as long as training loss keeps decreasing. Each time two consecutive epochs fail to decrease training loss by at least tol, or fail to increase validation score by at least tol if ‘early_stopping’ is on, the current learning rate is divided by 5.\n",
    "# learning_rate_init : double, optional, default 0.001\n",
    "# max_iter : Maximum number of iterations.\n",
    "# tol :Tolerance for the optimization.\n",
    "# verbose : \n",
    "# validation_fraction : The proportion of training data to set aside as validation set for early stopping. \n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''Multi-layer Perceptron classifier'''\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "classifier = MLPClassifier()\n",
    "parameters = {\"hidden_layer_sizes\":[(5, 2),(10,8,5)],  \"max_iter\": [200], \"alpha\": [0.00001,0.1]}\n",
    "#hidden_layer_sizes : The ith element represents the number of neurons in the ith hidden layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#DEFINE YOUR GRIDSEARCH \n",
    "'''\n",
    "GS perfoms an exhaustive search over specified parameter values for an estimator.\n",
    "GS uses a Stratified K-Folds cross-validator\n",
    "(The folds are made by preserving the percentage of samples for each class.)\n",
    "If refit=True the model is retrained on the whole training set with the best found params\n",
    "'''\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "gs = GridSearchCV(classifier, parameters, cv=3, scoring = 'accuracy', verbose=50, n_jobs=-1, refit=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TRAIN YOUR CLASSIFIER\n",
    "gs = gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#summarize the results of your GRIDSEARCH\n",
    "print('***GRIDSEARCH RESULTS***')\n",
    "\n",
    "print(\"Best score: %f using %s\" % (gs.best_score_, gs.best_params_))\n",
    "means = gs.cv_results_['mean_test_score']\n",
    "stds = gs.cv_results_['std_test_score']\n",
    "params = gs.cv_results_['params']\n",
    "\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEST ON YOUR TEST SET \n",
    "best_model = gs.best_estimator_\n",
    "y_pred = best_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is your prediction on the TEST SET\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EVALUATE YOUR PREDICTION (on the y_test that you left aside)\n",
    "from sklearn.metrics import f1_score\n",
    "print('***RESULTS ON TEST SET***')\n",
    "print(\"f1_score: \", f1_score(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#PRINT SOME FURTHER METRICS\n",
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#CONFUSION MATRIX\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(confusion_matrix(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot confusion matrix\n",
    "sns.heatmap(confusion_matrix(y_test, y_pred), annot=True, fmt='d', cmap=\"Blues\"); #annot=True to annotate cells fmt: format\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "model=MLPClassifier(hidden_layer_sizes=(100, 20), alpha=1e-05, max_iter=200)\n",
    "model.fit(X_train, y_train)\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "y_probs = model.predict_proba(X_test) #predict_proba gives the probabilities for the target (0 and 1 in your case) \n",
    "\n",
    "fpr, tpr, thresholds=metrics.roc_curve(y_test,  y_probs[:,1])\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot(fpr, tpr, label='ROC')\n",
    "plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "auc = metrics.roc_auc_score(y_test, y_probs[:,1])\n",
    "print('AUC: %.2f' % auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
